{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<h2>Preprocess Train samples</h2>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = []\n",
    "train_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    random_younger = randint(13, 64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(1)\n",
    "    \n",
    "    random_older = randint(65, 100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(0)\n",
    "\n",
    "for i in range(1000):\n",
    "    random_younger = randint(13, 64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(0)\n",
    "    \n",
    "    random_older = randint(65, 100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100\n"
     ]
    }
   ],
   "source": [
    "print (len(train_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = np.array(train_samples)\n",
    "train_labels = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\krishnamoorthy\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int32 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_train_samples = scaler.fit_transform((train_samples).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\krishnamoorthy\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(16, input_shape=(1,), activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1890 samples, validate on 210 samples\n",
      "Epoch 1/20\n",
      " - 0s - loss: 0.6777 - acc: 0.5217 - val_loss: 0.6610 - val_acc: 0.5524\n",
      "Epoch 2/20\n",
      " - 0s - loss: 0.6556 - acc: 0.5619 - val_loss: 0.6366 - val_acc: 0.6381\n",
      "Epoch 3/20\n",
      " - 0s - loss: 0.6345 - acc: 0.6159 - val_loss: 0.6089 - val_acc: 0.6952\n",
      "Epoch 4/20\n",
      " - 0s - loss: 0.6055 - acc: 0.6952 - val_loss: 0.5683 - val_acc: 0.7714\n",
      "Epoch 5/20\n",
      " - 0s - loss: 0.5729 - acc: 0.7513 - val_loss: 0.5330 - val_acc: 0.8143\n",
      "Epoch 6/20\n",
      " - 0s - loss: 0.5433 - acc: 0.7841 - val_loss: 0.4981 - val_acc: 0.8429\n",
      "Epoch 7/20\n",
      " - 0s - loss: 0.5142 - acc: 0.8053 - val_loss: 0.4640 - val_acc: 0.8667\n",
      "Epoch 8/20\n",
      " - 0s - loss: 0.4857 - acc: 0.8339 - val_loss: 0.4307 - val_acc: 0.8857\n",
      "Epoch 9/20\n",
      " - 0s - loss: 0.4582 - acc: 0.8513 - val_loss: 0.3988 - val_acc: 0.9048\n",
      "Epoch 10/20\n",
      " - 0s - loss: 0.4329 - acc: 0.8762 - val_loss: 0.3680 - val_acc: 0.9143\n",
      "Epoch 11/20\n",
      " - 0s - loss: 0.4098 - acc: 0.8889 - val_loss: 0.3406 - val_acc: 0.9238\n",
      "Epoch 12/20\n",
      " - 0s - loss: 0.3894 - acc: 0.8942 - val_loss: 0.3164 - val_acc: 0.9476\n",
      "Epoch 13/20\n",
      " - 0s - loss: 0.3718 - acc: 0.9063 - val_loss: 0.2945 - val_acc: 0.9476\n",
      "Epoch 14/20\n",
      " - 0s - loss: 0.3567 - acc: 0.9069 - val_loss: 0.2762 - val_acc: 0.9714\n",
      "Epoch 15/20\n",
      " - 0s - loss: 0.3441 - acc: 0.9143 - val_loss: 0.2584 - val_acc: 0.9571\n",
      "Epoch 16/20\n",
      " - 0s - loss: 0.3335 - acc: 0.9159 - val_loss: 0.2439 - val_acc: 0.9714\n",
      "Epoch 17/20\n",
      " - 0s - loss: 0.3246 - acc: 0.9196 - val_loss: 0.2317 - val_acc: 0.9714\n",
      "Epoch 18/20\n",
      " - 0s - loss: 0.3173 - acc: 0.9196 - val_loss: 0.2207 - val_acc: 0.9714\n",
      "Epoch 19/20\n",
      " - 0s - loss: 0.3111 - acc: 0.9259 - val_loss: 0.2105 - val_acc: 0.9714\n",
      "Epoch 20/20\n",
      " - 0s - loss: 0.3060 - acc: 0.9201 - val_loss: 0.2022 - val_acc: 0.9762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c206c963c8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_train_samples, train_labels, validation_split=0.1, batch_size=10, epochs=20, shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<h2>Preprocess Test Samples</h2>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = []\n",
    "test_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    random_younger = randint(13, 64)\n",
    "    test_samples.append(random_younger)\n",
    "    test_labels.append(1)\n",
    "    \n",
    "    random_older = randint(65, 100)\n",
    "    test_samples.append(random_older)\n",
    "    test_labels.append(0)\n",
    "\n",
    "for i in range(200):\n",
    "    random_younger = randint(13, 64)\n",
    "    test_samples.append(random_younger)\n",
    "    test_labels.append(0)\n",
    "    \n",
    "    random_older = randint(65, 100)\n",
    "    test_samples.append(random_older)\n",
    "    test_labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = np.array(test_samples)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\krishnamoorthy\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int32 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_test_samples = scaler.fit_transform((test_samples).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(scaled_test_samples, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9317646  0.0682354 ]\n",
      " [0.13868909 0.86131096]\n",
      " [0.9293507  0.0706493 ]\n",
      " [0.06946582 0.9305341 ]\n",
      " [0.92789257 0.0721074 ]\n",
      " [0.08264156 0.9173584 ]\n",
      " [0.9204371  0.07956286]\n",
      " [0.05014196 0.94985807]\n",
      " [0.8531197  0.1468803 ]\n",
      " [0.16350043 0.8364995 ]\n",
      " [0.4795308  0.5204691 ]\n",
      " [0.31858966 0.6814103 ]\n",
      " [0.4554117  0.54458827]\n",
      " [0.10746142 0.8925386 ]\n",
      " [0.82713693 0.17286299]\n",
      " [0.04522196 0.954778  ]\n",
      " [0.9306059  0.0693941 ]\n",
      " [0.03672861 0.9632713 ]\n",
      " [0.78155553 0.21844453]\n",
      " [0.29793164 0.7020684 ]\n",
      " [0.9244179  0.07558206]\n",
      " [0.16350044 0.8364995 ]\n",
      " [0.66670537 0.3332946 ]\n",
      " [0.05559588 0.9444041 ]\n",
      " [0.9329087  0.06709126]\n",
      " [0.2236036  0.77639645]\n",
      " [0.93365604 0.06634401]\n",
      " [0.04762164 0.9523784 ]\n",
      " [0.92891896 0.07108109]\n",
      " [0.27806666 0.7219333 ]\n",
      " [0.9306059  0.0693941 ]\n",
      " [0.19176231 0.80823773]\n",
      " [0.82713693 0.17286299]\n",
      " [0.17718962 0.8228104 ]\n",
      " [0.92848474 0.0715153 ]\n",
      " [0.31858966 0.6814103 ]\n",
      " [0.78155553 0.21844453]\n",
      " [0.29793164 0.7020683 ]\n",
      " [0.92935073 0.0706493 ]\n",
      " [0.03869585 0.9613041 ]\n",
      " [0.62234426 0.3776558 ]\n",
      " [0.08264156 0.9173584 ]\n",
      " [0.86485195 0.13514806]\n",
      " [0.36205634 0.6379436 ]\n",
      " [0.9280481  0.07195194]\n",
      " [0.05014196 0.94985807]\n",
      " [0.79764825 0.2023518 ]\n",
      " [0.20723167 0.7927683 ]\n",
      " [0.92848474 0.0715153 ]\n",
      " [0.05559588 0.9444041 ]\n",
      " [0.9338662  0.06613386]\n",
      " [0.13868909 0.86131096]\n",
      " [0.9204371  0.07956286]\n",
      " [0.07573653 0.9242635 ]\n",
      " [0.9280481  0.07195194]\n",
      " [0.17718962 0.8228104 ]\n",
      " [0.8405567  0.15944327]\n",
      " [0.2236036  0.77639645]\n",
      " [0.68788004 0.31211993]\n",
      " [0.22360356 0.77639645]\n",
      " [0.93365604 0.06634401]\n",
      " [0.08264156 0.9173584 ]\n",
      " [0.93252707 0.0674729 ]\n",
      " [0.31858966 0.6814103 ]\n",
      " [0.9204371  0.07956286]\n",
      " [0.05943978 0.94056016]\n",
      " [0.9308152  0.06918481]\n",
      " [0.2236036  0.77639645]\n",
      " [0.8128392  0.18716078]\n",
      " [0.09851422 0.90148574]\n",
      " [0.9293507  0.0706493 ]\n",
      " [0.10746142 0.8925386 ]\n",
      " [0.8531197  0.1468803 ]\n",
      " [0.05278829 0.9472117 ]\n",
      " [0.8757835  0.12421651]\n",
      " [0.2590374  0.7409626 ]\n",
      " [0.5037456  0.4962544 ]\n",
      " [0.04762164 0.9523784 ]\n",
      " [0.89476097 0.10523897]\n",
      " [0.05278829 0.9472117 ]\n",
      " [0.9321469  0.06785317]\n",
      " [0.19176231 0.80823773]\n",
      " [0.72790873 0.2720913 ]\n",
      " [0.240876   0.7591239 ]\n",
      " [0.8757835  0.12421651]\n",
      " [0.09023663 0.9097634 ]\n",
      " [0.92760897 0.07239109]\n",
      " [0.20723167 0.7927683 ]\n",
      " [0.8405567  0.15944326]\n",
      " [0.240876   0.759124  ]\n",
      " [0.9319385  0.0680615 ]\n",
      " [0.09023663 0.9097634 ]\n",
      " [0.59931344 0.40068662]\n",
      " [0.05278829 0.9472117 ]\n",
      " [0.6448359  0.35516408]\n",
      " [0.06946582 0.9305341 ]\n",
      " [0.93328166 0.06671835]\n",
      " [0.2236036  0.77639645]\n",
      " [0.9204371  0.07956286]\n",
      " [0.04293775 0.9570622 ]\n",
      " [0.9306059  0.0693941 ]\n",
      " [0.04293777 0.9570622 ]\n",
      " [0.92891896 0.0710811 ]\n",
      " [0.05943978 0.94056016]\n",
      " [0.74667245 0.25332755]\n",
      " [0.09023663 0.9097634 ]\n",
      " [0.59931344 0.40068662]\n",
      " [0.17718962 0.8228104 ]\n",
      " [0.9028713  0.09712871]\n",
      " [0.16350043 0.8364995 ]\n",
      " [0.9293507  0.0706493 ]\n",
      " [0.03672861 0.9632713 ]\n",
      " [0.9319385  0.0680615 ]\n",
      " [0.05559588 0.9444041 ]\n",
      " [0.9317646  0.0682354 ]\n",
      " [0.04522196 0.954778  ]\n",
      " [0.9293507  0.0706493 ]\n",
      " [0.08264156 0.9173584 ]\n",
      " [0.9157695  0.08423048]\n",
      " [0.29793164 0.7020684 ]\n",
      " [0.74667245 0.25332755]\n",
      " [0.04293777 0.9570622 ]\n",
      " [0.82713693 0.17286299]\n",
      " [0.31858966 0.6814103 ]\n",
      " [0.5520097  0.44799024]\n",
      " [0.03672861 0.9632713 ]\n",
      " [0.930207   0.06979301]\n",
      " [0.2236036  0.77639645]\n",
      " [0.47953084 0.5204691 ]\n",
      " [0.07573651 0.9242635 ]\n",
      " [0.92789257 0.0721074 ]\n",
      " [0.2590374  0.7409626 ]\n",
      " [0.93252707 0.0674729 ]\n",
      " [0.27806666 0.72193336]\n",
      " [0.9309941  0.06900585]\n",
      " [0.10746142 0.8925386 ]\n",
      " [0.5037456  0.4962544 ]\n",
      " [0.36205634 0.6379436 ]\n",
      " [0.8531197  0.1468803 ]\n",
      " [0.27806666 0.7219333 ]\n",
      " [0.59931344 0.40068662]\n",
      " [0.11711563 0.8828843 ]\n",
      " [0.81283927 0.18716073]\n",
      " [0.04076401 0.959236  ]\n",
      " [0.82713693 0.17286299]\n",
      " [0.11711563 0.8828843 ]\n",
      " [0.8405567  0.15944327]\n",
      " [0.06946582 0.9305341 ]\n",
      " [0.89476097 0.10523897]\n",
      " [0.05559588 0.9444041 ]\n",
      " [0.4795308  0.5204691 ]\n",
      " [0.33998612 0.6600138 ]\n",
      " [0.68788004 0.31211996]\n",
      " [0.17718962 0.8228104 ]\n",
      " [0.93365604 0.06634401]\n",
      " [0.05278829 0.9472117 ]\n",
      " [0.66670537 0.3332946 ]\n",
      " [0.15067509 0.8493249 ]\n",
      " [0.9338662  0.06613387]\n",
      " [0.08264156 0.9173584 ]\n",
      " [0.92789257 0.0721074 ]\n",
      " [0.27806666 0.72193336]\n",
      " [0.52794296 0.47205704]\n",
      " [0.36205634 0.6379436 ]\n",
      " [0.8405567  0.15944327]\n",
      " [0.11711563 0.8828843 ]\n",
      " [0.89476097 0.10523897]\n",
      " [0.16350044 0.8364995 ]\n",
      " [0.92891896 0.07108109]\n",
      " [0.10746142 0.8925386 ]\n",
      " [0.9308152  0.06918481]\n",
      " [0.04762164 0.9523784 ]\n",
      " [0.93252707 0.0674729 ]\n",
      " [0.27806666 0.72193336]\n",
      " [0.92978007 0.07021995]\n",
      " [0.08264156 0.9173584 ]\n",
      " [0.78155553 0.21844453]\n",
      " [0.06946582 0.9305341 ]\n",
      " [0.93328166 0.06671835]\n",
      " [0.43150005 0.5685    ]\n",
      " [0.8531197  0.1468803 ]\n",
      " [0.31858966 0.6814103 ]\n",
      " [0.9317646  0.0682354 ]\n",
      " [0.03672861 0.9632713 ]\n",
      " [0.74667245 0.25332755]\n",
      " [0.03672861 0.9632713 ]\n",
      " [0.9308152  0.06918481]\n",
      " [0.31858966 0.6814103 ]\n",
      " [0.9204371  0.07956286]\n",
      " [0.33998612 0.6600138 ]\n",
      " [0.86485195 0.13514806]\n",
      " [0.20723167 0.7927683 ]\n",
      " [0.8405567  0.15944327]\n",
      " [0.03869584 0.9613041 ]\n",
      " [0.86485195 0.13514806]\n",
      " [0.09851422 0.90148574]\n",
      " [0.9306059  0.0693941 ]\n",
      " [0.07573653 0.9242635 ]\n",
      " [0.9309941  0.06900585]\n",
      " [0.07573651 0.9242635 ]\n",
      " [0.9321469  0.06785317]\n",
      " [0.05278829 0.9472117 ]\n",
      " [0.9244179  0.07558206]\n",
      " [0.03869584 0.9613041 ]\n",
      " [0.79764825 0.2023518 ]\n",
      " [0.09023663 0.9097634 ]\n",
      " [0.9313804  0.06861962]\n",
      " [0.05278829 0.9472117 ]\n",
      " [0.89476097 0.10523897]\n",
      " [0.10746142 0.8925386 ]\n",
      " [0.9340148  0.06598528]\n",
      " [0.07573653 0.9242635 ]\n",
      " [0.93328166 0.06671835]\n",
      " [0.09851422 0.90148574]\n",
      " [0.92891896 0.0710811 ]\n",
      " [0.27806666 0.72193336]\n",
      " [0.4795308  0.5204691 ]\n",
      " [0.29793164 0.7020683 ]\n",
      " [0.9329087  0.06709126]\n",
      " [0.43150005 0.5685    ]\n",
      " [0.86485195 0.13514806]\n",
      " [0.06402754 0.93597245]\n",
      " [0.66670537 0.3332946 ]\n",
      " [0.29793164 0.7020683 ]\n",
      " [0.9308152  0.06918481]\n",
      " [0.13868909 0.86131096]\n",
      " [0.79764825 0.2023518 ]\n",
      " [0.17718962 0.8228104 ]\n",
      " [0.82713693 0.17286299]\n",
      " [0.09851422 0.90148574]\n",
      " [0.76456076 0.23543918]\n",
      " [0.08264156 0.9173584 ]\n",
      " [0.86485195 0.13514806]\n",
      " [0.09023663 0.9097634 ]\n",
      " [0.9028713  0.0971287 ]\n",
      " [0.19176231 0.80823773]\n",
      " [0.68788004 0.31211996]\n",
      " [0.05943978 0.94056016]\n",
      " [0.9317646  0.0682354 ]\n",
      " [0.04522196 0.954778  ]\n",
      " [0.9329087  0.06709126]\n",
      " [0.33998612 0.6600138 ]\n",
      " [0.92848474 0.0715153 ]\n",
      " [0.33998612 0.6600138 ]\n",
      " [0.9321469  0.06785317]\n",
      " [0.05278829 0.9472117 ]\n",
      " [0.78155553 0.21844453]\n",
      " [0.07573653 0.9242635 ]\n",
      " [0.92978007 0.07021996]\n",
      " [0.19176231 0.80823773]\n",
      " [0.92891896 0.0710811 ]\n",
      " [0.05559588 0.9444041 ]\n",
      " [0.82713693 0.17286299]\n",
      " [0.19176231 0.80823773]\n",
      " [0.9329053  0.06709464]\n",
      " [0.16350044 0.8364995 ]\n",
      " [0.8757835  0.12421651]\n",
      " [0.36205634 0.6379436 ]\n",
      " [0.79764825 0.2023518 ]\n",
      " [0.15067504 0.8493249 ]\n",
      " [0.74667245 0.25332755]\n",
      " [0.16350044 0.8364995 ]\n",
      " [0.82713693 0.17286299]\n",
      " [0.17718962 0.8228104 ]\n",
      " [0.92848474 0.0715153 ]\n",
      " [0.15067509 0.8493249 ]\n",
      " [0.86485195 0.13514806]\n",
      " [0.04762164 0.9523784 ]\n",
      " [0.92978007 0.07021996]\n",
      " [0.17718965 0.8228104 ]\n",
      " [0.92848474 0.0715153 ]\n",
      " [0.33998612 0.6600138 ]\n",
      " [0.9157695  0.08423046]\n",
      " [0.05943978 0.94056016]\n",
      " [0.9157695  0.08423046]\n",
      " [0.05559588 0.9444041 ]\n",
      " [0.92978007 0.07021995]\n",
      " [0.09851422 0.90148574]\n",
      " [0.74667245 0.25332758]\n",
      " [0.04293775 0.9570622 ]\n",
      " [0.52794296 0.47205704]\n",
      " [0.17718962 0.8228104 ]\n",
      " [0.79764825 0.2023518 ]\n",
      " [0.17718962 0.8228104 ]\n",
      " [0.92760897 0.07239109]\n",
      " [0.38472408 0.6152759 ]\n",
      " [0.68788004 0.31211996]\n",
      " [0.31858966 0.6814103 ]\n",
      " [0.57583517 0.42416483]\n",
      " [0.04762164 0.9523784 ]\n",
      " [0.82713693 0.17286299]\n",
      " [0.27806666 0.72193336]\n",
      " [0.8531197  0.1468803 ]\n",
      " [0.09023663 0.9097634 ]\n",
      " [0.8405567  0.15944327]\n",
      " [0.15067509 0.8493249 ]\n",
      " [0.79764825 0.2023518 ]\n",
      " [0.20723167 0.7927683 ]\n",
      " [0.9280481  0.07195196]\n",
      " [0.04293775 0.9570622 ]\n",
      " [0.9338662  0.06613386]\n",
      " [0.04522196 0.954778  ]\n",
      " [0.9308152  0.06918481]\n",
      " [0.04762164 0.9523784 ]\n",
      " [0.93328166 0.06671835]\n",
      " [0.06402754 0.93597245]\n",
      " [0.8405567  0.15944327]\n",
      " [0.4315001  0.5685    ]\n",
      " [0.93252707 0.0674729 ]\n",
      " [0.43150005 0.5685    ]\n",
      " [0.93365604 0.06634401]\n",
      " [0.15067509 0.8493249 ]\n",
      " [0.92848474 0.0715153 ]\n",
      " [0.04076401 0.959236  ]\n",
      " [0.9329087  0.06709126]\n",
      " [0.29793164 0.7020683 ]\n",
      " [0.9280481  0.07195194]\n",
      " [0.2236036  0.77639645]\n",
      " [0.62234426 0.3776558 ]\n",
      " [0.27806666 0.7219333 ]\n",
      " [0.68788004 0.31211996]\n",
      " [0.16350044 0.8364995 ]\n",
      " [0.9340148  0.06598528]\n",
      " [0.15067509 0.8493249 ]\n",
      " [0.9157695  0.08423046]\n",
      " [0.06946582 0.9305341 ]\n",
      " [0.4554117  0.54458827]\n",
      " [0.38472408 0.6152759 ]\n",
      " [0.93328166 0.06671835]\n",
      " [0.04076401 0.959236  ]\n",
      " [0.92891896 0.0710811 ]\n",
      " [0.17718962 0.8228104 ]\n",
      " [0.62234426 0.3776558 ]\n",
      " [0.4079035  0.5920965 ]\n",
      " [0.9306059  0.0693941 ]\n",
      " [0.05943978 0.94056016]\n",
      " [0.9204371  0.07956286]\n",
      " [0.04522196 0.954778  ]\n",
      " [0.92891896 0.07108109]\n",
      " [0.07573651 0.9242635 ]\n",
      " [0.66670537 0.3332946 ]\n",
      " [0.38472408 0.6152759 ]\n",
      " [0.9293507  0.0706493 ]\n",
      " [0.29793164 0.7020683 ]\n",
      " [0.76456076 0.23543918]\n",
      " [0.2590374  0.7409626 ]\n",
      " [0.9313804  0.06861962]\n",
      " [0.11711563 0.8828843 ]\n",
      " [0.708298   0.291702  ]\n",
      " [0.19176231 0.80823773]\n",
      " [0.9340148  0.06598528]\n",
      " [0.38472408 0.6152759 ]\n",
      " [0.74667245 0.25332755]\n",
      " [0.03869584 0.9613041 ]\n",
      " [0.93365604 0.06634401]\n",
      " [0.27806666 0.72193336]\n",
      " [0.59931344 0.40068662]\n",
      " [0.04293777 0.9570622 ]\n",
      " [0.9280481  0.07195196]\n",
      " [0.09023663 0.9097634 ]\n",
      " [0.9321469  0.06785317]\n",
      " [0.04293777 0.9570622 ]\n",
      " [0.930207   0.06979301]\n",
      " [0.33998612 0.6600138 ]\n",
      " [0.57583517 0.4241648 ]\n",
      " [0.240876   0.7591239 ]\n",
      " [0.92760897 0.07239109]\n",
      " [0.15067509 0.8493249 ]\n",
      " [0.5520097  0.44799024]\n",
      " [0.15067504 0.8493249 ]\n",
      " [0.9309941  0.06900585]\n",
      " [0.29793164 0.7020683 ]\n",
      " [0.89476097 0.10523897]\n",
      " [0.03869584 0.9613041 ]\n",
      " [0.72790873 0.2720913 ]\n",
      " [0.4315001  0.5685    ]\n",
      " [0.59931344 0.40068662]\n",
      " [0.4315001  0.5685    ]\n",
      " [0.92760897 0.07239109]\n",
      " [0.20723167 0.7927683 ]\n",
      " [0.4795308  0.5204691 ]\n",
      " [0.19176231 0.80823773]\n",
      " [0.9157695  0.08423046]\n",
      " [0.33998612 0.6600138 ]\n",
      " [0.9306059  0.0693941 ]\n",
      " [0.08264156 0.9173584 ]\n",
      " [0.82713693 0.17286299]\n",
      " [0.2236036  0.77639645]\n",
      " [0.72790873 0.2720913 ]\n",
      " [0.05943978 0.94056016]\n",
      " [0.9338662  0.06613386]\n",
      " [0.04076401 0.959236  ]\n",
      " [0.92848474 0.0715153 ]\n",
      " [0.06946582 0.9305341 ]\n",
      " [0.79764825 0.2023518 ]\n",
      " [0.04076401 0.959236  ]\n",
      " [0.9340148  0.06598528]\n",
      " [0.31858966 0.6814103 ]\n",
      " [0.92789257 0.0721074 ]\n",
      " [0.3847241  0.6152759 ]\n",
      " [0.9244179  0.07558206]\n",
      " [0.12751327 0.8724867 ]\n",
      " [0.78155553 0.21844453]\n",
      " [0.06946582 0.9305341 ]\n",
      " [0.4795308  0.5204691 ]\n",
      " [0.10746142 0.8925386 ]\n",
      " [0.8757835  0.12421651]\n",
      " [0.15067509 0.8493249 ]\n",
      " [0.92891896 0.07108109]\n",
      " [0.2590374  0.7409626 ]\n",
      " [0.72790873 0.2720913 ]\n",
      " [0.36205634 0.6379436 ]\n",
      " [0.66670537 0.3332946 ]\n",
      " [0.03869584 0.9613041 ]\n",
      " [0.79764825 0.2023518 ]\n",
      " [0.05943978 0.94056016]\n",
      " [0.930207   0.06979301]\n",
      " [0.2590374  0.7409626 ]\n",
      " [0.92760897 0.07239109]\n",
      " [0.09023663 0.9097634 ]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_classes = model.predict_classes(scaled_test_samples, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 0 1 0 1 0 1 1 1 1 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 1 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 1 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 1 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 1 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 1 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 1 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(predictions_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<h2>Confusion Matrix</h2>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(test_labels, predictions_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[194  16]\n",
      " [  8 202]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_plot_labels = ['no_side_effects', 'has_side_effects']\n",
    "plot_confusion_matrix(cm, cm_plot_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<h2>Save and Load the Model</h2>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('medical_trial_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "from keras.models import load_model\n",
    "new_model = load_model('medical_trial_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.44262213,  0.42178112,  0.5751037 , -0.5672708 ,  0.5457782 ,\n",
       "         -0.02653545, -0.48460233,  0.42908853,  0.4308401 ,  0.19902821,\n",
       "         -0.3735192 , -0.5388699 ,  0.46047652,  0.08405053, -0.46766126,\n",
       "         -0.47070923]], dtype=float32),\n",
       " array([-0.10020333, -0.11867305, -0.11224386,  0.        , -0.10283364,\n",
       "         0.        ,  0.        , -0.09853988, -0.08028448,  0.20718697,\n",
       "         0.        ,  0.        , -0.10689277,  0.16497546,  0.        ,\n",
       "         0.        ], dtype=float32),\n",
       " array([[-0.21111952, -0.30616233, -0.05664818,  0.19685054, -0.18188594,\n",
       "         -0.10288257, -0.12918961, -0.09167241,  0.24119739,  0.2644071 ,\n",
       "          0.4014606 ,  0.13836092,  0.12056452, -0.3413786 , -0.12480801,\n",
       "          0.48937988, -0.21245392, -0.2585644 ,  0.41161913,  0.16571632,\n",
       "          0.10144668,  0.28096718, -0.02068349, -0.08220169,  0.34703693,\n",
       "         -0.09369049,  0.1262646 ,  0.23568763,  0.52491456,  0.10085151,\n",
       "         -0.10874943,  0.01852255],\n",
       "        [-0.4341229 , -0.46476343, -0.10187438,  0.14897916,  0.08828135,\n",
       "          0.2251058 , -0.4045524 , -0.17054963,  0.30637747,  0.29333764,\n",
       "          0.43296131, -0.31740993, -0.15960573, -0.35848385, -0.01370651,\n",
       "          0.06299082, -0.42768896, -0.13501762, -0.11338621, -0.06585811,\n",
       "         -0.00515151,  0.3490126 ,  0.11106151, -0.26415452, -0.07414339,\n",
       "          0.14284126, -0.14691426, -0.26303613,  0.24311651, -0.43474287,\n",
       "          0.50647855, -0.37765878],\n",
       "        [-0.32601368,  0.04708372,  0.08900008, -0.23357229,  0.0629755 ,\n",
       "          0.24555328, -0.37728867,  0.10622378,  0.3234272 , -0.00774413,\n",
       "          0.00323594, -0.0266237 , -0.18214105, -0.1717779 , -0.10743271,\n",
       "          0.04189466, -0.11249688, -0.03116575,  0.49763077,  0.16303694,\n",
       "         -0.14176808, -0.34502888,  0.41445753,  0.27679572,  0.36421832,\n",
       "          0.13230121,  0.20435825, -0.13106185,  0.4030706 , -0.05164545,\n",
       "          0.35012692, -0.01897785],\n",
       "        [-0.30273658, -0.23480894, -0.00467551,  0.29819188,  0.30096266,\n",
       "         -0.07817271,  0.2599692 ,  0.24915436,  0.05443165,  0.10852519,\n",
       "         -0.13407949, -0.01673862, -0.3267973 ,  0.20502242,  0.02475756,\n",
       "          0.33201548,  0.33461675, -0.09393209, -0.3487831 , -0.21468492,\n",
       "         -0.24660584, -0.0092321 ,  0.3453357 , -0.24747947,  0.02599195,\n",
       "          0.26044175, -0.33508134,  0.2692193 ,  0.230306  , -0.10615139,\n",
       "          0.14764991,  0.11882976],\n",
       "        [-0.04237746,  0.10710485,  0.11796843,  0.14567119,  0.16678596,\n",
       "         -0.08215179,  0.16899975, -0.32564348,  0.10492262, -0.34293178,\n",
       "          0.3455419 ,  0.09410373, -0.22272448, -0.08588343,  0.07543605,\n",
       "          0.50869143,  0.00636588, -0.31325114, -0.06777477, -0.166478  ,\n",
       "         -0.11353703, -0.15426631,  0.51669514,  0.09341782, -0.1694528 ,\n",
       "         -0.071157  , -0.12542735, -0.43220922,  0.32664654, -0.3360554 ,\n",
       "          0.3416543 , -0.18748444],\n",
       "        [-0.2807002 , -0.33950508, -0.29287517, -0.34450388,  0.2271032 ,\n",
       "         -0.16051829,  0.07252544,  0.03082004, -0.2821496 ,  0.23864844,\n",
       "          0.13843209, -0.1457481 , -0.18281178,  0.2805777 , -0.06030262,\n",
       "          0.16018644, -0.14336377,  0.23504815,  0.13033769,  0.058099  ,\n",
       "         -0.18760625,  0.3457363 ,  0.10014284, -0.17301887, -0.06068513,\n",
       "          0.28866538, -0.29197794,  0.09825721, -0.29274854, -0.10451069,\n",
       "         -0.07352087, -0.14812636],\n",
       "        [ 0.1670104 ,  0.11224583,  0.01617047,  0.04914895, -0.1766994 ,\n",
       "         -0.04020438, -0.05072162,  0.18209139,  0.15611783,  0.05717018,\n",
       "          0.0874123 ,  0.26680306, -0.0840838 , -0.12200677,  0.07108977,\n",
       "          0.18725535, -0.18511578,  0.04642281, -0.02496248,  0.03671116,\n",
       "          0.29334703,  0.26774618, -0.2929372 ,  0.02185482,  0.09179592,\n",
       "          0.25499913,  0.16763338, -0.06658605, -0.33556664, -0.25387052,\n",
       "          0.17947158, -0.13744129],\n",
       "        [-0.10837196,  0.01808391, -0.38694006, -0.30717513,  0.01622901,\n",
       "         -0.31947812, -0.15999886, -0.16804606,  0.23112085, -0.21597177,\n",
       "         -0.07660396, -0.10285245,  0.10290909, -0.19160078, -0.3136812 ,\n",
       "          0.20913668, -0.34352684,  0.2928843 , -0.07726732, -0.35847202,\n",
       "         -0.03295184, -0.03919539,  0.52343285, -0.2605208 ,  0.39570677,\n",
       "          0.18325609, -0.14646265,  0.13932154,  0.20942579,  0.08809184,\n",
       "          0.51822317, -0.40829772],\n",
       "        [-0.19754493, -0.41411862, -0.00715314,  0.24687494, -0.17950498,\n",
       "          0.09659554, -0.12848674,  0.04498566,  0.32265395, -0.24705358,\n",
       "          0.23401095, -0.27165702, -0.05745165, -0.07475023,  0.00391354,\n",
       "          0.15935266,  0.22116369,  0.30536106,  0.39153776, -0.01682484,\n",
       "          0.27142635, -0.03921802,  0.03741497, -0.1545047 ,  0.215496  ,\n",
       "         -0.36986062, -0.00299183,  0.05616181, -0.17449485, -0.39151502,\n",
       "          0.49173287, -0.09509387],\n",
       "        [ 0.41447902,  0.07511857, -0.00705652, -0.16333741, -0.1800092 ,\n",
       "         -0.205179  ,  0.33608207,  0.32312164, -0.06586272, -0.01211607,\n",
       "          0.3479048 ,  0.16263066,  0.13421394,  0.37141702,  0.02807789,\n",
       "          0.0091721 ,  0.28064838, -0.30697462,  0.14725901, -0.11107772,\n",
       "         -0.21060705,  0.02810438, -0.02913467, -0.2479048 ,  0.27146003,\n",
       "         -0.06308419,  0.07950787,  0.14842999,  0.32077616,  0.29093358,\n",
       "         -0.14197224,  0.18267249],\n",
       "        [ 0.17609182, -0.10877216, -0.02083182,  0.2599351 ,  0.11252129,\n",
       "         -0.2865615 , -0.05631039, -0.1997528 ,  0.09299973,  0.21393916,\n",
       "          0.26165572, -0.03881776, -0.1790029 ,  0.30137417,  0.3435209 ,\n",
       "          0.19836792, -0.1988409 , -0.06933939,  0.33294097, -0.28196502,\n",
       "         -0.1656925 , -0.22623594, -0.35076308,  0.20586386, -0.2321085 ,\n",
       "          0.09235698,  0.13020298, -0.02012789, -0.21368115,  0.1414583 ,\n",
       "         -0.01125202,  0.24711338],\n",
       "        [ 0.3173065 , -0.16266593, -0.2401755 ,  0.2705572 , -0.12031382,\n",
       "         -0.17646295, -0.08289224, -0.14333056, -0.15959755,  0.0968076 ,\n",
       "          0.22053608, -0.27936405,  0.09460974, -0.0924803 ,  0.18656161,\n",
       "          0.17869833, -0.1484991 ,  0.02718768,  0.04281723, -0.12073226,\n",
       "         -0.2745514 ,  0.29533485, -0.1545294 , -0.03048778,  0.28103587,\n",
       "          0.0082688 ,  0.04296088, -0.01081571, -0.02487692,  0.11627692,\n",
       "         -0.01594591, -0.34399608],\n",
       "        [ 0.21022864,  0.0134362 , -0.18528944, -0.3048554 ,  0.16912134,\n",
       "         -0.00390303, -0.1094602 , -0.45548493,  0.17811286, -0.21110095,\n",
       "          0.35644165, -0.29297337, -0.15756889, -0.14889766, -0.33753186,\n",
       "          0.36304244, -0.37115115,  0.01929835,  0.24394283, -0.24180649,\n",
       "         -0.2495192 , -0.24010381, -0.03294813,  0.29034784,  0.31021   ,\n",
       "         -0.2781576 , -0.13249783, -0.3135251 ,  0.36930636,  0.17541584,\n",
       "          0.34555978, -0.00903042],\n",
       "        [-0.05423304,  0.08920048,  0.03115928,  0.22789356, -0.22572309,\n",
       "          0.03418418,  0.26752326,  0.3279658 ,  0.05656788, -0.02942479,\n",
       "         -0.12491944, -0.09020133, -0.00805082,  0.29221517,  0.10588205,\n",
       "          0.19856404,  0.37118584,  0.15491763,  0.3448756 ,  0.21932498,\n",
       "         -0.29918155, -0.0240286 , -0.24007107, -0.24150261, -0.0144163 ,\n",
       "          0.32521093, -0.08208872,  0.06016947,  0.24879077,  0.08150072,\n",
       "          0.30323562,  0.15793486],\n",
       "        [-0.17085321, -0.30030346, -0.32440168,  0.3031734 ,  0.2683418 ,\n",
       "         -0.12801288,  0.19472846, -0.1231949 ,  0.20531914,  0.10932326,\n",
       "          0.25206944, -0.27429464, -0.3405568 , -0.33800945, -0.01985916,\n",
       "          0.31579039, -0.06787622, -0.0606263 , -0.00771835,  0.04869226,\n",
       "         -0.22136645,  0.04395571, -0.04850537,  0.32025924,  0.03733316,\n",
       "          0.3384818 ,  0.01079726, -0.20782965, -0.16981319, -0.20116715,\n",
       "          0.21210095, -0.32876498],\n",
       "        [ 0.25944874, -0.16593955, -0.01892805,  0.1592795 ,  0.02769572,\n",
       "         -0.12347214, -0.09509921,  0.32854977, -0.2409601 ,  0.32406643,\n",
       "         -0.06067848, -0.02956888,  0.12889221, -0.1766269 , -0.21170698,\n",
       "         -0.24080542, -0.23067999, -0.19783005, -0.21077748, -0.30140164,\n",
       "          0.05069077,  0.02522218,  0.3272566 , -0.23293121, -0.00120851,\n",
       "         -0.12621388, -0.08259264,  0.19033232,  0.01318344,  0.22163871,\n",
       "          0.14646897,  0.24321875]], dtype=float32),\n",
       " array([ 0.20102431,  0.20857808,  0.11964379, -0.00636307,  0.00219667,\n",
       "        -0.00143863,  0.15795146,  0.13007659, -0.05280018, -0.00413017,\n",
       "        -0.07815663,  0.16159439, -0.03136165,  0.21205527, -0.02663263,\n",
       "        -0.08254541,  0.16842012, -0.0006717 , -0.09775383,  0.12705505,\n",
       "        -0.00096654, -0.00700693, -0.0351148 ,  0.        , -0.07985625,\n",
       "         0.09089961, -0.00717088,  0.17812319, -0.11359493,  0.14076215,\n",
       "        -0.06923374,  0.20916665], dtype=float32),\n",
       " array([[ 0.6118059 , -0.39692077],\n",
       "        [ 0.53675485, -0.10233001],\n",
       "        [ 0.21666121, -0.33230108],\n",
       "        [-0.01199246,  0.02008297],\n",
       "        [-0.30871648, -0.37504822],\n",
       "        [ 0.17951064,  0.13950844],\n",
       "        [ 0.66592664, -0.24799925],\n",
       "        [ 0.25443977, -0.479147  ],\n",
       "        [-0.36725408,  0.52430636],\n",
       "        [ 0.21056734,  0.24745162],\n",
       "        [-0.4479631 ,  0.47925746],\n",
       "        [ 0.22469899, -0.15892749],\n",
       "        [-0.39797294, -0.20725875],\n",
       "        [ 0.7062383 , -0.21496662],\n",
       "        [ 0.29427174,  0.32468113],\n",
       "        [-0.41536123,  0.03840633],\n",
       "        [ 0.6969107 , -0.44950688],\n",
       "        [ 0.36942312,  0.20142072],\n",
       "        [-0.16491097,  0.42902562],\n",
       "        [ 0.19631875, -0.10802112],\n",
       "        [-0.28124765,  0.19695519],\n",
       "        [-0.40201536, -0.21087253],\n",
       "        [-0.35996494,  0.5225512 ],\n",
       "        [-0.39296412,  0.3070216 ],\n",
       "        [-0.08807107,  0.5633953 ],\n",
       "        [-0.07800381, -0.20820211],\n",
       "        [-0.3425662 ,  0.20322396],\n",
       "        [ 0.661939  , -0.31120178],\n",
       "        [-0.07354786,  0.47058204],\n",
       "        [ 0.09100497, -0.600105  ],\n",
       "        [-0.33314988,  0.30106696],\n",
       "        [ 0.73238045, -0.2457554 ]], dtype=float32),\n",
       " array([ 0.10969752, -0.10969753], dtype=float32)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.optimizers.Adam at 0x2c209a02978>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<h2>Convert the Model to Json</h2>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"class_name\": \"Sequential\", \"config\": [{\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_1\", \"trainable\": true, \"batch_input_shape\": [null, 1], \"dtype\": \"float32\", \"units\": 16, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_2\", \"trainable\": true, \"units\": 32, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_3\", \"trainable\": true, \"units\": 2, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}], \"keras_version\": \"2.1.6\", \"backend\": \"tensorflow\"}'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_string = model.to_json()\n",
    "json_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model reconstruction from Json\n",
    "from keras.models import model_from_json\n",
    "model_architecture = model_from_json(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_architecture.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
